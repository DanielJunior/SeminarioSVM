{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align='left' style=\"width:400px;height:120px;overflow:hidden;\">\n",
    "<a href='http://www.uff.br'>\n",
    "<img align='left' style='display: block;height: 92%' src='imgs/UFF.png' alt='UFF logo' title='UFF logo'/>\n",
    "</a>\n",
    "<a href='http://www.ic.uff.br'>\n",
    "<img align='left' style='display: block;height: 100%' src='imgs/logo-ic.png' alt='IC logo' title='IC logo'/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Machine Learning: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Daniel Junior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Utiliza conceitos de teorias como: Teoria do Aprendizado Estatístico, Teoria das Categorias e Teoria das Restrições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Teoria do Aprendizado Estatístico</b> estabelece as condições matemáticas para a escolha de um classificador\n",
    "a partir de um conjunto de treinamento.</br>\n",
    "Definições necessárias:\n",
    "    * Espaço de entradas\n",
    "    * Espaço de saída\n",
    "    * Considerações (Distribuição Conjunta dos dados de treinamento é uma delas.)\n",
    "    * Função de Perda\n",
    "    * Risco do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Usa um algoritmo <b>Instance Based Learning<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Pode ser visto com uma generalização do Perceptron.\n",
    "No entanto acrescenta recursos cruciais: <b>Kernel, Maximização da Margem e Variáveis de Folga</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possui 3 componentes principais: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Support Vectors\n",
    "* Vetor de pesos\n",
    "* Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Support Vectors</b> são um subconjunto do conjunto de treinamento que será utilizado como a base de criação da <i>fronteira de decisão</i>. São a partir deles que pode ser calculada a margem máxima entre duas classes, aumentando a <i>confiança</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Vetor de pesos</b> assim como nos métodos vistos anteriormente determina o grau de contribuição de cada vetor de suporte para a fronteira de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Kernel</b> é uma função que tem como objetivo mapear um dado espaço em outro. Isso é utilizado para casos onde os dados não são linearmente separáveis, então é necessário definir uma transformação onde a representação dos dados neste novo espaço possa ser linearmente separável. Então se utiliza o produto escalar para definir a similaridade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVM: Classificação Binária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Margem\n",
    "* Confiança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Margens Rígidas vs Margens Suaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<a href=\"#\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 0.5em;\" target=\"_blank\">\n",
    "<img src=\"imgs/rigida.png\" />\n",
    "</a><a href=\"#\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 1em;\" target=\"_blank\"></a><a href=\"#\" target=\"_blank\"><img src=\"imgs/suave.png\" /></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Para o caso de dados com natureza linearmente separável, a fronteira é um hiperplano, como visto na classificação\n",
    "linear. Neste caso o SVM pode ser classificado em duas categorias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Margens rígidas: </b>Dado um hiperplano separador, o objetivo é maximizar a distância para os hiperplanos paralelos à ele, entre os quais não existem nenhum dado de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "O hiperplano que divide os dados pode ser representado por uma equação do tipo:\n",
    "$$f(x) = w \\cdot x + b = 0$$\n",
    "\n",
    "Podemos utilizar uma função para auxiliar na obtenção das classificações:\n",
    "$$g(x) = sgn(f(x)) = \\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  +1,\\quad \\textrm{se}\\quad w \\cdot x + b > 0\\\\\n",
    "                  −1,\\quad \\textrm{se}\\quad w \\cdot x + b < 0\n",
    "                \\end{array}\n",
    "              \\right.$$ \n",
    "                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Após alguns passos resulta que o problema de maximização da margem de separação dos dados em relação ao hiperplano é o problema de otimização:\n",
    "\n",
    "$$ Minimizar_{w,b} \\quad \\frac{1}{2} \\left| \\left| w \\right| \\right|²$$\n",
    "\n",
    "\n",
    "$$ \\textrm{Com as restrições:} \\quad y_i(w · x_i + b) − 1 >= 0; \\quad ∀i = 1, . . . , n$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "O problema de otimização obtido é quadrático, cuja solução possui uma ampla e estabelecida teoria matemática. Como a função objetivo sendo minimizada é convexa e os pontos que satisfazem as restrições formam um conjunto convexo, esse problema possui um único mínimo global . Problemas desse tipo podem ser solucionados com a introdução de uma função Lagrangiana, que engloba as restrições à função objetivo, associadas a parâmetros denominados multiplicadores de Lagrange $\\alpha_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resolvendo a minimização da função Lagrangiana temos o seguinte resultado:\n",
    "    $$ g(x) = sgn(f(x)) = sgn(\\sum\\limits_{x_i \\in SV} y_i α_i^∗ x_i · x + b^∗) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Margens suaves:</b> Relaxa a restrição da margem rígida, permitindo algumas (limitadas) violações. Para isso na equação utilizada na maximização da margem é introduzida uma <i>variável de folga</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Aqui podemos fazer a observação da percepção do SVM ser uma \"modernização\" do Perceptron. A fronteira de decisão no\n",
    "caso da classificação binária, é uma equação que retorna -1,1 como resposta de prediçao. No entanto os recursos de kernel, maximização da margem e variáveis o tornam muito mais poderoso. São estes recursos que também o ajudam a evitar o overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "No entanto, a maior parte dos problemas reais não possui todas as características que são necessárias para aplicação da solução acima. Mais especificamente, os dados não podem ser separados por um hiperplano no espaço original das entradas. Então é necessário realizar o mapeamento utilizando alguma função Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVM Não-Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/nonlinear.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos práticos a transformação de um conjunto de entrada de um espaço para outro demanda um esforço computacional muito grande.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A solução é utilizar uma função de similaridade que possa ser calculada em termos do espaço original, mas com seu resultado referindo ao espaço transformado."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
