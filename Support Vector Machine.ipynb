{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align='left' style=\"width:400px;height:120px;overflow:hidden;\">\n",
    "<a href='http://www.uff.br'>\n",
    "<img align='left' style='display: block;height: 92%' src='imgs/UFF.png' alt='UFF logo' title='UFF logo'/>\n",
    "</a>\n",
    "<a href='http://www.ic.uff.br'>\n",
    "<img align='left' style='display: block;height: 100%' src='imgs/logo-ic.png' alt='IC logo' title='IC logo'/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Machine Learning: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Daniel Junior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Utiliza conceitos de teorias como: Teoria do Aprendizado Estatístico, Teoria das Categorias e Teoria das Restrições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Teoria do Aprendizado Estatístico</b> estabelece as condições matemáticas para a escolha de um classificador\n",
    "a partir de um conjunto de treinamento.</br>\n",
    "Definições necessárias:\n",
    "* Espaço de entradas\n",
    "* Espaço de saída\n",
    "* Considerações (Distribuição Conjunta dos dados de treinamento é uma delas.)\n",
    "* Função de Perda\n",
    "* Risco do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Usa um algoritmo <b>Instance Based Learning<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Pode ser visto com uma generalização do Perceptron.\n",
    "No entanto acrescenta recursos cruciais: <b>Kernel, Maximização da Margem e Variáveis de Folga</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possui 3 componentes principais: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Support Vectors\n",
    "* Vetor de pesos\n",
    "* Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Support Vectors</b> são um subconjunto do conjunto de treinamento que será utilizado como a base de criação da <i>fronteira de decisão</i>. São a partir deles que pode ser calculada a margem máxima entre duas classes, aumentando a <i>confiança</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Vetor de pesos</b> assim como nos métodos vistos anteriormente determina o grau de contribuição das features na classificação, ou ainda, qual lado do hiperplano um novo exemplo estará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Kernel</b> é uma função que tem como objetivo mapear um dado espaço em outro. Isso é utilizado para casos onde os dados não são linearmente separáveis, então é necessário definir uma transformação onde a representação dos dados neste novo espaço possa ser linearmente separável. Então se utiliza o produto escalar para definir a similaridade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVM: Classificação Binária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Margem\n",
    "* Confiança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/svm.jpg\" style=\"margin: 0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Para o caso de dados com natureza linearmente separável, a fronteira é um hiperplano, como visto na classificação\n",
    "linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "O hiperplano que divide os dados pode ser representado por uma equação do tipo:\n",
    "$$f(x) = w \\cdot x + b = 0$$\n",
    "\n",
    "Podemos utilizar uma função para auxiliar na obtenção das classificações:\n",
    "$$g(x) = sgn(f(x)) = \\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  +1,\\quad \\textrm{se}\\quad w \\cdot x + b > 0\\\\\n",
    "                  −1,\\quad \\textrm{se}\\quad w \\cdot x + b < 0\n",
    "                \\end{array}\n",
    "              \\right.$$ \n",
    "                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problema\n",
    "<img src=\"imgs/margin.jpg\" style=\"margin: 0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Após alguns passos resulta que o problema de maximização da margem \n",
    "de separação dos dados em relação ao hiperplano é o problema de otimização:\n",
    "\n",
    "$$ Minimizar_{w,b} \\quad \\frac{1}{2} \\left| \\left| w \\right| \\right|² \\quad \\quad \\textrm{(1)} $$ \n",
    "\n",
    "\n",
    "$$ \\textrm{Com as restrições:} \\quad y_i(w · x_i + b) − 1 >= 0; \\quad ∀i = 1, . . . , n \\quad \\quad \\textrm{(2)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "O problema de otimização obtido é quadrático, cuja solução possui uma ampla e estabelecida teoria matemática. Como a função objetivo sendo minimizada é convexa e os pontos que satisfazem as restrições formam um conjunto convexo, esse problema possui um único mínimo global . Problemas desse tipo podem ser solucionados com a introdução de uma função Lagrangiana, que engloba as restrições à função objetivo, associadas a parâmetros denominados multiplicadores de Lagrange $\\alpha_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resolvendo a minimização da função Lagrangiana temos o seguinte resultado:\n",
    "    $$ g(x) = sgn(f(x)) = sgn(\\sum\\limits_{x_i \\in SV} y_i α_i^∗ x_i · x + b^∗) \\quad \\quad (3)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Margens Rígidas vs Margens Suaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<a href=\"#\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 0.5em;\" target=\"_blank\">\n",
    "<img src=\"imgs/rigida.png\" />\n",
    "</a><a href=\"#\" style=\"clear: left; float: left; margin-bottom: 1em; margin-right: 1em;\" target=\"_blank\"></a><a href=\"#\" target=\"_blank\"><img src=\"imgs/suave.png\" /></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Margens rígidas: </b>Dado um hiperplano separador, o objetivo é maximizar a distância para os hiperplanos paralelos à ele, entre os quais não existem nenhum dado de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b>Margens suaves:</b> Relaxa a restrição da margem rígida, permitindo algumas (limitadas) violações. Para isso na equação utilizada na maximização da margem são introduzidas <i>variáveis de folga</i> às equações (1) e (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Aqui podemos fazer a observação da percepção do SVM ser uma \"modernização\" do Perceptron. A fronteira de decisão no\n",
    "caso da classificação binária, é uma equação que retorna -1,1 como resposta de prediçao. No entanto os recursos de kernel, maximização da margem e variáveis de folga o tornam muito mais poderoso. São estes recursos que também o ajudam a evitar o overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "É possível perceber que temos um problema de otimização de difícil solução analítica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo SMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A abordagem clássica (<i>Quadratic Programming Solvers</i>) para resolver o problema de otimização que temos são inviáveis para grande datasets, por questões de tempo e consumo de memória.\n",
    "<br/><br/>\n",
    "O <b>SMO</b> reduz esse problema a resolver muitos sub-problemas menores de otimização envolvendo apenas dois multiplicadores de Lagrange por vez. Ou seja, utiliza uma abordagem iterativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "class SVM():\n",
    "    \"\"\"\n",
    "        Simple implementation of a Support Vector Machine using the\n",
    "        Sequential Minimal Optimization (SMO) algorithm for training.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=10000, kernel_type='linear', C=1.0, epsilon=0.001):\n",
    "        self.kernels = {\n",
    "            'linear' : self.kernel_linear,\n",
    "            'quadratic' : self.kernel_quadratic\n",
    "        }\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel_type = kernel_type\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "    def fit(self, X, y):\n",
    "        # Initialization\n",
    "        n, d = X.shape[0], X.shape[1]\n",
    "        alpha = np.zeros((n))\n",
    "        kernel = self.kernels[self.kernel_type]\n",
    "        count = 0\n",
    "        while True:\n",
    "            count += 1\n",
    "            alpha_prev = np.copy(alpha)\n",
    "            for j in range(0, n):\n",
    "                i = self.get_rnd_int(0, n-1, j) # Get random int i~=j\n",
    "                x_i, x_j, y_i, y_j = X[i,:], X[j,:], y[i], y[j]\n",
    "                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n",
    "                if k_ij == 0:\n",
    "                    continue\n",
    "                alpha_prime_j, alpha_prime_i = alpha[j], alpha[i]\n",
    "                (L, H) = self.compute_L_H(self.C, alpha_prime_j, alpha_prime_i, y_j, y_i)\n",
    "\n",
    "                # Compute model parameters\n",
    "                self.w = self.calc_w(alpha, y, X)\n",
    "                self.b = self.calc_b(X, y, self.w)\n",
    "\n",
    "                # Compute E_i, E_j\n",
    "                E_i = self.E(x_i, y_i, self.w, self.b)\n",
    "                E_j = self.E(x_j, y_j, self.w, self.b)\n",
    "\n",
    "                # Set new alpha values\n",
    "                alpha[j] = alpha_prime_j + float(y_j * (E_i - E_j))/k_ij\n",
    "                alpha[j] = max(alpha[j], L)\n",
    "                alpha[j] = min(alpha[j], H)\n",
    "\n",
    "                alpha[i] = alpha_prime_i + y_i*y_j * (alpha_prime_j - alpha[j])\n",
    "\n",
    "            # Check convergence\n",
    "            diff = np.linalg.norm(alpha - alpha_prev)\n",
    "            if diff < self.epsilon:\n",
    "                break\n",
    "\n",
    "            if count >= self.max_iter:\n",
    "                print(\"Iteration number exceeded the max of %d iterations\" % (self.max_iter))\n",
    "                return\n",
    "        # Compute final model parameters\n",
    "        self.b = self.calc_b(X, y, self.w)\n",
    "        if self.kernel_type == 'linear':\n",
    "            self.w = self.calc_w(alpha, y, X)\n",
    "        # Get support vectors\n",
    "        alpha_idx = np.where(alpha > 0)[0]\n",
    "        support_vectors = X[alpha_idx, :]\n",
    "        return support_vectors, count\n",
    "    def predict(self, X):\n",
    "        return self.h(X, self.w, self.b)\n",
    "    def calc_b(self, X, y, w):\n",
    "        b_tmp = y - np.dot(w.T, X.T)\n",
    "        return np.mean(b_tmp)\n",
    "    def calc_w(self, alpha, y, X):\n",
    "        return np.dot(alpha * y, X)\n",
    "    # Prediction\n",
    "    def h(self, X, w, b):\n",
    "        return np.sign(np.dot(w.T, X.T) + b).astype(int)\n",
    "    # Prediction error\n",
    "    def E(self, x_k, y_k, w, b):\n",
    "        return self.h(x_k, w, b) - y_k\n",
    "    def compute_L_H(self, C, alpha_prime_j, alpha_prime_i, y_j, y_i):\n",
    "        if(y_i != y_j):\n",
    "            return (max(0, alpha_prime_j - alpha_prime_i), min(C, C - alpha_prime_i + alpha_prime_j))\n",
    "        else:\n",
    "            return (max(0, alpha_prime_i + alpha_prime_j - C), min(C, alpha_prime_i + alpha_prime_j))\n",
    "    def get_rnd_int(self, a,b,z):\n",
    "        i = z\n",
    "        while i == z:\n",
    "            i = rnd.randint(a,b)\n",
    "        return i\n",
    "    # Define kernels\n",
    "    def kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "    def kernel_quadratic(self, x1, x2):\n",
    "        return (np.dot(x1, x2.T) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def calc_acc(y, y_hat):\n",
    "    idx = np.where(y_hat == 1)\n",
    "    TP = np.sum(y_hat[idx] == y[idx])\n",
    "    idx = np.where(y_hat == -1)\n",
    "    TN = np.sum(y_hat[idx] == y[idx])\n",
    "    return float(TP + TN)/len(y)\n",
    "\n",
    "\n",
    "def readData(filename, header=True):\n",
    "    data, header = [], None\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',')\n",
    "        if header:\n",
    "            header = spamreader.next()\n",
    "        for row in spamreader:\n",
    "            data.append(row)\n",
    "    return (np.array(data), np.array(header))\n",
    "\n",
    "filename = \"data/iris-virginica.txt\"\n",
    "(data, _) = readData(filename, header=False)\n",
    "data = data.astype(float)\n",
    "\n",
    "positives = np.array([np.array(row) for row in data[:] if row[4] == 1])\n",
    "negatives = [np.asarray(row) for row in data[:] if row[4] == -1]\n",
    "\n",
    "training_data = positives[:int(len(positives) * 0.8)]\n",
    "neg = negatives[:int(len(negatives) * 0.8) ]\n",
    "training_data = np.concatenate((training_data,neg))\n",
    "\n",
    "test_data = positives[int(len(positives)* 0.8 ) :]\n",
    "neg = negatives[int(len(negatives) * 0.8) :]\n",
    "test_data = np.concatenate((test_data,neg))\n",
    "\n",
    "X  = training_data[:,0:-1]\n",
    "y = training_data[:,-1].astype(int)\n",
    "\n",
    "model = SVM()\n",
    "\n",
    "# Fit model\n",
    "support_vectors, iterations = model.fit(X, y)\n",
    "\n",
    "# Support vector count\n",
    "sv_count = support_vectors.shape[0]\n",
    "\n",
    "X_t = test_data[:,0:-1]\n",
    "y_t = test_data[:,-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de vetores de suporte: 63\n",
      "Viés:\t\t162.757\n",
      "Pesos:\t\t[ -6.6185702   -2.36149285 -27.92193074 -15.54596774]\n",
      "Convergência em 11 iterações.\n",
      "\n",
      "********** Dados de treinamento ************\n",
      "\n",
      "Acurácia:\t0.775\n",
      "\n",
      "********* Dados de teste *************\n",
      "\n",
      "Acurácia:\t0.433\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantidade de vetores de suporte: %d\" % (sv_count))\n",
    "print(\"Viés:\\t\\t%.3f\" % (model.b))\n",
    "print(\"Pesos:\\t\\t\" + str(model.w))\n",
    "print(\"Convergência em %d iterações.\" % (iterations))\n",
    "\n",
    "y_hat = model.predict(X)\n",
    "acc = calc_acc(y, y_hat)\n",
    "\n",
    "print(\"\\n********** Dados de treinamento ************\\n\")\n",
    "print(\"Acurácia:\\t%.3f\" % (acc))\n",
    "\n",
    "y_hat = model.predict(X_t)\n",
    "acc = calc_acc(y_t, y_hat)\n",
    "\n",
    "print(\"\\n********* Dados de teste *************\\n\")\n",
    "print(\"Acurácia:\\t%.3f\" % (acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f85ed824e80>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHndJREFUeJzt3XmUVPWZ//H3o4GfE8dwREZRFIkKKshiK6AMDq2gICaK\nO05GMYOKIMYNFwIJODpjfjg/IaJg5IcxeFR0xAgqsig0ouxC04Ag6CgKBDegB5S1+5k/vlcpEeim\nqqtuLZ/XOXW4/a1b1Q/3dNfTz3e75u6IiIgk46C4AxARkdylJCIiIklTEhERkaQpiYiISNKURERE\nJGlKIiIikrScSiJm1sXMVpjZSjO7N+54REQKneXKOhEzOwhYCXQE1gHzge7uviLWwEREClguVSJt\ngFXuvtrddwJjgUtijklEpKDlUhJpAHyW8PWaqE1ERGKSS0lERESyzE/iDuAArAUaJnx9bNT2PTPL\njQEeEZEs4+6WzOtyqRKZD5xkZsebWW2gOzBhz5PcXQ93Bg0aFHsM2fLQtdC10LXY92Pr1tT+9s6Z\nJOLuFUBfYAqwDBjr7svjjUpEJHe9/Ta0bJnae+RSdxbuPgk4Oe44RERyWXk53HsvvPYaPPYYXHpp\n8u+VM5WIHJji4uK4Q8gauha76VrsVqjX4pVXoFmzcLx0KXTrltr75cxiw+owM8+n/4+ISE1Zvx5u\nvRUWL4ZRo6BDh93PmRleAAPrIiJygNxh9Gho0QKaNIGysh8mkFTl1JiIiIhU34cfwk03webNMHVq\n6oPoe6NKREQkz+zaBUOGwFlnwS9+AbNnpyeBgCoREZG8smgR9OwJ9erBvHlwwgnp/X6qRERE8sDW\nrWHabpcucNttMHly+hMIKImIiOS86dPDwPnq1WHgvEcPsKTmWh04dWeJiOSojRvh7rthyhR4/HH4\n5S8zH4MqERGRHOMO48bBaafBIYeERYNxJBBQJSIiklPWroW+fWHFCnjxRfjHf4w3HlUiIiI5oLIS\n/vQnaNUqjH+UlsafQECViIhI1lu5Em68EbZvD4Pop50Wd0S7qRIREclSO3fCQw9Bu3Zw+eXw7rvZ\nlUBAlYiISFZasCAsGjzmGHjvPTj++Lgj2jtVIiIiWeSbb6Bfv7BdyT33wMSJ2ZtAQElERCRrTJ0K\nzZuHbduXLIFf/SpziwaTpe4sEZGYff013HUXlJTAyJFw4YVxR1R9qkRERGLiDi+8EAbL69QJiwZz\nKYGAKhERkVh89hn06QMffwx//WvYtj0XqRIREcmgykoYMQKKiqBNG1i4MHcTCKgSERHJmOXLw6JB\nd5gxA5o2jTui1KkSERFJsx074IEH4Jxz4JprYObM/EggoEpERCSt5syBG26ARo3CXQePOy7uiGqW\nkoiISBps2QIDB4bZV0OHwtVXZ/+aj2SoO0tEpIZNmhSm7W7aFKbtdu+enwkEVImIiNSYr76C22+H\nWbNg1Cg4//y4I0o/VSIiIilyh2efDdXHUUeFLUsKIYGAKhERkZSsXg29e4c7Dr76KrRuHXdEmaVK\nREQkCRUV8OijcMYZ0L592Lq90BIIqBIRETlgy5aFabu1aoUbRZ18ctwRxUeViIhINW3fDoMGQXEx\nXH992HW3kBMIqBIREamWWbNC9dGkCZSWQoMGcUeUHZRERET243/+B377W3j55TAGcvnl+bvmIxnq\nzhIR2YfXXgvTdrdtC+MgV1yhBLInVSIiInv44gu47TaYPx+efhrOOy/uiLKXKhERkYg7jBkT7nPe\nsCGUlSmBVEWViIgI4Q6DvXrBl1/CG2+Em0ZJ1VSJiEhBq6iARx4JCwU7dYJ585RADoQqEREpWGVl\nYdruoYfC7NnQuHHcEeUeVSIiUnC2bYMBA0Ll0asXTJumBJIsVSIiUlDefjvc57x5c1i8GI4+Ou6I\ncpuSiIgUhPJyuPfesPZj+HC49NK4I8oP6s4Skbw3fjw0axaOly5VAqlJqkREJG+tXw+33hq6rZ59\nFjp0iDui/KNKRETyjjs89RS0aBEGzBcvVgJJF1UiIpJXPvwwzLgqL4epU6Fly7gjym9pq0TMbJCZ\nrTGzhdGjS8Jz/c1slZktN7MLEtqLzKzMzFaa2bCE9tpmNjZ6zWwza5iuuEUkN+3aBQ8/DGedBRdd\nBHPmKIFkQrorkUfc/ZHEBjM7FbgKOBU4FnjTzBq7uwMjgZ7uPt/MJppZZ3efDPQENrh7YzO7GhgC\ndE9z7CKSIxYtgp494YgjworzE06IO6LCke4xkb1tmnwJMNbdd7n7J8AqoI2Z1QcOc/f50XljgG4J\nr/lLdPwS0DF9IYtIrti6NUzb7dIl7Lo7ZYoSSKalO4n0NbNSM/v/ZlYnamsAfJZwztqorQGwJqF9\nTdT2g9e4ewWwyczqpjVyEclq06eHgfPVq8P2JT166F4fcUipO8vMpgJHJTYBDgwARgD/5u5uZg8C\n/w+4IZXvt8f32avBgwd/f1xcXExxcXENfUsRyQYbN8I998DkyfD44/DLX8YdUe4pKSmhpKSkRt7L\nwlBEepnZ8cCr7t7CzO4D3N3/b/TcJGAQsBqY7u6nRu3dgQ7u3vu7c9x9rpkdDPzN3Y/cy/fxTPx/\nRCQe48bBb34D3brBQw/Bz34Wd0T5wcxw96TquHTOzqqf8OVlwNLoeALQPZpx9XPgJGCeu68Hys2s\njZkZcB0wPuE1PaLjK4Fp6YpbRLLPunVw2WUwcCC88EKoQJRAskM6x0SGRNN1S4EOwB0A7v4+8CLw\nPjAR6JNQPtwCjAZWAqvcfVLUPhqoZ2argNuB+9IYt4hkicpKePLJMFX3tNPCLKz27eOOShJlpDsr\nU9SdJZI/Vq6Em24K27aPGhV23ZX0yMruLBGRZOzcGcY72rULGyW++64SSDbTticikjUWLAiLBo8+\nOhw3ahR3RFIVVSIiErtvvoF+/eAXvwjTd994QwkkVyiJiEis3nwzLBpcvx6WLIFf/UqLBnOJurNE\nJBYbNsBdd4X7m48cCV27xh2RJEOViIhklHtY69GsWVjrsXSpEkguUyUiIhmzZg306QMffQQvvwxn\nnx13RJIqVSIiknaVlTBiBJx+Opx5Zlg0qASSH1SJiEhaLV8ON94YurFmzICmTeOOSGqSKhERSYsd\nO+CBB+Ccc+Caa2DmTCWQfKRKRERq3Ny5cMMNcPzxoevquOPijkjSRUlERGrMli27d9odOhSuvlpr\nPvKdurNEpEZMmhR22t24MUzb7d5dCaQQqBIRkZR89RXccQe8807Ytv2CC+KOSDJJlYiIJMUdnnsu\nVB9HHhmqDyWQwqNKREQO2OrV0Lt3WDw4YQK0aRN3RBIXVSIiUm0VFfDoo3DGGeEOg++9pwRS6FSJ\niEi1LFsWpu3WqhVuFHXyyXFHJNlAlYiI7Nf27TB4MBQXw/XXQ0mJEojspkpERPZp1qxQfTRuDKWl\n0KBB3BFJtlESEZEf2bwZ+vcPO+0++ihcfrnWfMjeqTtLRH7g9dfDvT62bg3Tdq+4QglE9k2ViIgA\n8MUXcNttMH8+/PnP0LFj3BFJLlAlIlLg3GHMGGjePGyUWFamBCLVp0pEpIB9/DH06gVffglvvAFF\nRXFHJLlGlYhIAaqoCLvstm4NnTrBvHlKIJIcVSIiBaasLEzbPfRQmD07TN8VSZYqEZECsW1buNdH\np05w000wbZoSiKROlYhIAXj77XCf8+bNYfFiOProuCOSfKEkIpLHysvhvvvg1Vdh+HC49NK4I5J8\no+4skTw1fnxYNFhZGRYNKoFIOqgSEckz69fDrbeGbqtnn4UOHeKOSPKZKhGRPOEOTz0FLVqEAfPF\ni5VAJP1UiYjkgY8+CjOuysth6lRo2TLuiKRQqBIRyWG7dsHDD0PbttC1K8yZowQimaVKRCRHLVoU\nFg3WrRtWnJ9wQtwRSSFSJSKSY7ZuDdN2O3cOA+hTpiiBSHyURERyyPTpYeD8k09gyZJwu1rd60Pi\npO4skRywcSPccw9MmgSPPw4XXxx3RCKBKhGRLDduHJx2GtSuDcuWKYFIdlElIpKl1q2Dvn1h+XJ4\n4QVo3z7uiER+TJWISJaprIRRo6BVq1CBLFqkBCLZS5WISBZZuTIsGty6Fd56K+y6K5LNVImIZIGd\nO+Ghh6Bdu7BR4qxZSiCSG1SJiMRswYKwaLB+/XDcqFHcEYlUnyoRkZh88w306wcXXRT+feMNJRDJ\nPUoiIjF4882waPBvfwv3+viXf9GiQclNKSURM7vCzJaaWYWZFe3xXH8zW2Vmy83sgoT2IjMrM7OV\nZjYsob22mY2NXjPbzBomPNcjOv8DM7sulZhF4rRhA/z619CzZ7jT4LPPwj/8Q9xRiSQv1UpkCXAp\nMCOx0cxOBa4CTgUuBEaYff931kigp7s3AZqYWeeovSewwd0bA8OAIdF7HQ78HmgNtAUGmVmdFOMW\nySh3ePHFcKfBww4L1UfXrnFHJZK6lAbW3f0DgIQE8Z1LgLHuvgv4xMxWAW3MbDVwmLvPj84bA3QD\nJkevGRS1vwQMj447A1PcvTz6XlOALsALqcQukilr1kCfPuGeHy+/DGefHXdEIjUnXWMiDYDPEr5e\nG7U1ANYktK+J2n7wGnevAMrNrO5+3kskq1VWwsiRcPrpcMYZsHChEojknyorETObChyV2AQ4MMDd\nX01XYNH3OWCDBw/+/ri4uJji4uIaCkek+lasCNN2Kythxgxo2jTuiER2KykpoaSkpEbeq8ok4u7n\nJ/G+a4HjEr4+NmrbV3via9aZ2cHAz9x9g5mtBYr3eM30fX3jxCQikmk7dsCQIfDHP8LgwdC7Nxyk\nOZCSZfb8A/v+++9P+r1q8sc7sXKYAHSPZlz9HDgJmOfu6wndVG2icZTrgPEJr+kRHV8JTIuOJwPn\nm1mdaJD9/KhNJKvMnRu6rWbPhvfeg1tuUQKR/JfSwLqZdSMMgNcDXjOzUne/0N3fN7MXgfeBnUAf\nd/foZbcATwOHABPdfVLUPhp4JhqE/xroDuDuG83sAWABoRvtfnfflErcIjVpyxYYODDstDt0KFx9\ntdZ8SOGw3Z/tuc/MPJ/+P5L9Jk+GXr2gQwd45BE44oi4IxI5cGaGuyf1p4/2zhJJwldfwZ13wsyZ\n8Kc/hfudixQi9diKHAB3eO65cJ+PevXCfc6VQKSQqRIRqaZPPw2zrT77DCZMgDZt4o5IJH6qRESq\nUFER9rkqKgr3+1iwQAlE5DuqRET2Y9mysGiwVi145x045ZS4IxLJLqpERPZi+/awWLC4GHr0gJIS\nJRCRvVElIrKHWbNC9dG4MZSWQgPt1CayT0oiIpHNm+G3v4Vx48K2JVdcoUWDIlVRd5YI8PrrYdru\nt9+Ge31ceaUSiEh1qBKRgvbFF3D77WHfq6eego4d445IJLeoEpGC5A5jxkDz5nDssWHRoBKIyIFT\nJSIF5+OP4eabQxUycWLYeVdEkqNKRApGRUXYZbd1azjvPJg3TwlEJFWqRKQglJWFabuHHhru99G4\ncdwRieQHVSKS17ZtC/f66NgRbroJpk1TAhGpSapEJG/NnAk33gjNmsHixXDMMXFHJJJ/lEQk75SX\nw333hZ12hw+Hyy6LOyKR/KXuLMkrEyaERYMVFWHzRCUQkfRSJSJ5Yf16+M1vwl5XzzwTNk4UkfRT\nJSI5zT2sNG/RAk46KYx9KIGIZI4qEclZH30UZlyVl8OUKdCqVdwRiRQeVSKSc3btgocfhrZtoWtX\nmDNHCUQkLqpEJKeUlkLPnnD44WHTxBNPjDsikcKmSkRywtat0L8/XHAB9O0LU6cqgYhkA1UikvVK\nSsKiwaKisH1J/fpxRyQi31ESkay1aRPcfTdMmgSPPw4XXxx3RCKyJ3VnSVZ6+eWwXUmtWuFOg0og\nItlJlYhklXXrwpjH++/DCy9A+/ZxRyQi+6NKRLJCZSWMGgUtW4YKpLRUCUQkF6gSkditXBkWDW7d\nGrZqb9487ohEpLpUiUhsdu6EP/wB2rWDbt1g1iwlEJFco0pEYvHee+FOg0ceCQsWQKNGcUckIslQ\nJSIZ9e23Ydpu165w551h+q4SiEjuUhKRjHnzzdBdtW4dLFkC114LZnFHJSKpUHeWpN2GDdCvH7z1\nFowcGaoQEckPqkQkbdzhxRfDnQb//u/DokElEJH8okpE0mLNGujTJ9zzY9w4OPvsuCMSkXRQJSI1\nqrIydFmdfjqccQYsXKgEIpLPVIlIjVmxIuy2u2tX2Hm3WbO4IxKRdFMlIinbsQMefDBsU3L11fDO\nO0ogIoVClYikZN68sGjwuONC11XDhnFHJCKZpCQiSdmyBX73O3j+eRg6FLp315oPkUKk7iw5YJMn\nh0WDGzaEabvXXKMEIlKoVIlItX31VdiqZOZMeOIJ6Nw57ohEJG6qRKRK7vDcc2HR4BFHhC1LlEBE\nBFSJSBU+/RR69w7/jh8PbdvGHZGIZBNVIrJXFRXw2GNhwWC7dmHrdiUQEdlTSknEzK4ws6VmVmFm\nRQntx5vZt2a2MHqMSHiuyMzKzGylmQ1LaK9tZmPNbJWZzTazhgnP9YjO/8DMrkslZqnasmVwzjnh\nHuczZ8KAAVC7dtxRiUg2SrUSWQJcCszYy3MfuntR9OiT0D4S6OnuTYAmZvZd73pPYIO7NwaGAUMA\nzOxw4PdAa6AtMMjM6qQYt+zF9u0weDAUF8N118GMGXDKKXFHJSLZLKUk4u4fuPsqYG8TPH/UZmb1\ngcPcfX7UNAboFh1fAvwlOn4JOC867gxMcfdyd98ETAG6pBK3/Njs2VBUBIsWhcfNN8NB6uwUkSqk\n82OiUdSVNd3M2kdtDYA1Ceesidq+e+4zAHevAMrNrG5ie2RtwmskRZs3w623wuWXhyrklVfg2GPj\njkpEckWVs7PMbCpwVGIT4MAAd391Hy9bBzR0943RWMkrZtb0AGNLavna4MGDvz8uLi6muLg4mbcp\nCK+/HrZr79QpLBqsWzfuiEQkE0pKSigpKamR9zJ3T/1NzKYDd7n7wv09T0gu09391Ki9O9DB3Xub\n2SRgkLvPNbODgb+5+5HROcXufnP0miei93hhL9/Ha+L/k++++AJuvx3mzoUnn4SOHeOOSETiZGa4\ne1J/uNdkd9b3AZhZPTM7KDo+ATgJ+G93X0/opmpjZgZcB4yPXjYB6BEdXwlMi44nA+ebWZ1okP38\nqE0OkDs880zYsqRBg7BoUAlERFKR0mJDM+sGDAfqAa+ZWam7Xwj8E/BvZrYDqAR6RYPiALcATwOH\nABPdfVLUPhp4xsxWAV8D3QGiLrEHgAWEbrT7E95LqumTT6BXL/j8c5g4Maz/EBFJVY10Z2ULdWf9\nWEUFDB8e7vfRrx/cdRfUqhV3VCKSTVLpztK2J3msrCzc6+OnPw1TeBs3jjsiEck3WgmQh7Ztg4ED\nw3jHTTfBtGlKICKSHqpE8szMmeE+582aweLFcMwxcUckIvlMSSRPlJfDfffBhAlhDOSyy+KOSEQK\ngbqz8sCECeFeHxUVYfNEJRARyRRVIjns88/DliWLFsGYMXDuuXFHJCKFRpVIDnKHP/85LBo88cQw\nC0sJRETioEokx3z0UVg0uHEjTJkCrVrFHZGIFDJVIjli1y74z/8Mdxfs0iXse6UEIiJxUyWSA0pL\noWdPOPzwkDxOPDHuiEREAlUiWWzrVujfHy64APr2halTlUBEJLuoEslSJSVh0eDpp4eB8/r1445I\nROTHlESyzKZNcPfdMGkSPPYYXHJJ3BGJiOyburOyyF//GhYN1qoV7jSoBCIi2U6VSBZYty4sGly2\nDJ5/Hs45J+6IRESqR5VIjNxh1Cho2RKaNg2zsJRARCSXqBKJyapVYZv2b78NW7U3bx53RCIiB06V\nSIbt3Al/+AOcfXYY85g1SwlERHKXKpEMeu+9cKfBI4+EBQugUaO4IxIRSY0qkQz49tswbbdrV7jz\nzjB9VwlERPKBkkiavfVW6K5auxaWLIFrrwWzuKMSEakZ6s5Kkw0boF+/kERGjICLLoo7IhGRmqdK\npIa5w3/9V1g0eOihYdGgEoiI5CtVIjVozRq45ZYwffell6Bdu7gjEhFJL1UiNaCyEkaODJslFhWF\n29UqgYhIIVAlkqIVK8Juu7t2hZ13mzWLOyIRkcxRJZKkHTvgwQehfXu46ip45x0lEBEpPKpEkjBv\nXlg0eOyxsHAhNGwYd0QiIvFQEjkA33wDAweGnXaHDoXu3bXmQ0QKm7qzqmny5DBt9+uvw7Tda65R\nAhERUSVSha+/hjvugJkz4YknoHPnuCMSEckeqkT2wT10WzVrBkccEbYsUQIREfkhVSJ78emn0Lt3\n+Hf8eGjbNu6IRESykyqRBBUV8NhjYcHg2WeHrduVQERE9k2VSGTZsrBo8OCDw5qPU06JOyIRkexX\n8JXI9u0weDB06BC2aZ8xQwlERKS6CroSmT07LBo88UQoLQ2LB0VEpPoKMols3gwDBoQt2//4R7jy\nSq35EBFJRsF1Z02cGBYNbtkSxkGuukoJREQkWQVTiXz5Jdx2G8ydC6NHQ6dOcUckIpL78r4ScYdn\nngnVR4MGYdGgEoiISM3I60rkk0+gVy/4/PPQjXXGGXFHJCKSX/KyEqmogGHD4Mwz4dxzYf58JRAR\nkXTIu0pkyZIwbffv/g5mzYImTeKOSEQkf5m7xx1DjTEzr1fP+Y//gJ494aC8rLNERGqWmeHuSc1T\nzbsksnatc8wxcUciIpI7UkkiKf2tbmZDzGy5mZWa2Tgz+1nCc/3NbFX0/AUJ7UVmVmZmK81sWEJ7\nbTMbG71mtpk1THiuR3T+B2Z23f5iUgIREcmcVDt8pgDN3L0VsAroD2BmTYGrgFOBC4ERZt8v6RsJ\n9HT3JkATM/vuLh09gQ3u3hgYBgyJ3utw4PdAa6AtMMjM6qQYd94rKSmJO4SsoWuxm67FbroWNSOl\nJOLub7p7ZfTlHOC73acuBsa6+y53/4SQYNqYWX3gMHefH503BugWHV8C/CU6fgk4LzruDExx93J3\n30RIXF1SibsQ6BdkN12L3XQtdtO1qBk1OfT8r8DE6LgB8FnCc2ujtgbAmoT2NVHbD17j7hVAuZnV\n3c97iYhIzKqc4mtmU4GjEpsABwa4+6vROQOAne7+fA3Gph2tRESynbun9ACuB94F/k9C233AvQlf\nTyKMZ9QHlie0dwdGJp4THR8MfJFwzhMJr3kCuHofsbgeeuihhx4H/kg2B6S02NDMugB3A//k7tsT\nnpoAPGtmQwldTycB89zdzazczNoA84HrgEcTXtMDmAtcCUyL2icD/x4Nph8EnE9IUj+S7BQ1ERFJ\nTqor1ocDtYGp0eSrOe7ex93fN7MXgfeBnUAf370g5RbgaeAQYKK7T4raRwPPmNkq4GtCBYK7bzSz\nB4AFhIx5fzTALiIiMcurxYYiIpJZObkxiJl1MbMV0QLEe/dxzqPRwsVSM2uV6RgzpaprYWb/bGaL\no8c7ZtY8jjgzoTo/F9F5rc1sp5ldlsn4MqmavyPFZrbIzJaa2fRMx5gp1fgd+ZmZTYg+K5aY2fUx\nhJl2ZjbazD43s7L9nHPgn5upDqxn+kFIfB8CxwO1gFLglD3OuRB4PTpuS+hmiz32mK7FWUCd6LhL\nIV+LhPPeAl4DLos77hh/LuoAy4AG0df14o47xmvRH3jou+tA6E7/Sdyxp+FatAdaAWX7eD6pz81c\nrETaAKvcfbW77wTGEhYqJrqEsJARd58L1DGzo8g/VV4Ld5/j7uXRl3PI3zU21fm5ALiVsJj1i0wG\nl2HVuRb/DIxz97UA7v5VhmPMlOpcCwcOi44PA752910ZjDEj3P0dYON+TknqczMXk8ieiw8TFyzu\n65x8XaBYnWuR6AbgjbRGFJ8qr4WZHQN0c/eR5Pc6pOr8XDQB6prZdDObb2bXZiy6zKrOtXgMaGpm\n64DFwG0Zii3bJPW5mXf3E5G9M7NzgV8TStpCNQxI7BPP50RSlZ8ARYTthQ4FZpvZbHf/MN6wYtEZ\nWOTu55nZiYTZpi3cfUvcgeWCXEwia4GGCV8fG7Xtec5xVZyTD6pzLTCzFsCTQBd33185m8uqcy3O\nBMZGm4HWAy40s53uPiFDMWZKda7FGuArd98GbDOzt4GWhPGDfFKda/Fr4CEAd//IzD4GTiEsKygk\nSX1u5mJ31nzgJDM73sxqE9aT7PkhMIGwkBEzOwvY5O6fZzbMjKjyWkRb6o8DrnX3j2KIMVOqvBbu\nfkL0+DlhXKRPHiYQqN7vyHigvZkdbGY/JQykLs9wnJlQnWuxGugEEI0BNAH+O6NRZo6x7wo8qc/N\nnKtE3L3CzPoSdvM9CBjt7svNrFd42p9094lm1tXMPgS+IfylkXeqcy2A3wF12b0d/053bxNf1OlR\nzWvxg5dkPMgMqebvyAozmwyUARXAk+7+foxhp0U1fy4eBJ5OmPp6j7tviCnktDGz54Bi4Agz+xQY\nRFgsntLnphYbiohI0nKxO0tERLKEkoiIiCRNSURERJKmJCIiIklTEhERkaQpiYiISNKUREREJGlK\nIiIikrT/BbyLBp305HXDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85ed858a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "first = np.sum(model.w * X[0:])\n",
    "last = np.sum(model.w * X[-1:])\n",
    "plt.plot([first, last])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "No entanto, a maior parte dos problemas reais não possui todas as características que são necessárias para aplicação da solução acima. Mais especificamente, os dados não podem ser separados por um hiperplano no espaço original das entradas. Então é necessário realizar o mapeamento utilizando alguma função Kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVM Não-Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/nonlinear.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos práticos a transformação de um conjunto de entrada de um espaço para outro demanda um esforço computacional muito grande.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A solução é utilizar uma função de similaridade que possa ser calculada em termos do espaço original, mas com seu resultado referindo ao espaço transformado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Utilizando uma função de kernel $\\theta$ apropriada, alteramos a equação (3) e obtemos o seguinte classificador:\n",
    "    $$ g(x) = sgn(f(x)) = sgn(\\sum\\limits_{x_i \\in SV} y_i α_i^∗ \\theta (x_i) · \\theta (x) + b^∗) $$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
